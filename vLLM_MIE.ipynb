{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('xxx.csv', sep=';')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "llm = LLM(\"mistralai/Mistral-7B-Instruct-v0.1\", max_model_len=32768/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokenizer for chat template\n",
    "tokenizer = llm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_template(df: pd.DataFrame, query: str, tokenizer):\n",
    "    llm_chat = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Your task is to write python code to return a list of all unique patients for the given dataframe using the pandas and matplotlib libraries.\n",
    "The dataset has an event-based structure, every line has the same number of columns, so each patient has multiple rows.\n",
    "Here are the first dataframe rows:\n",
    "{df.head(5)}\n",
    "\n",
    "The dataframe has the following columns:\n",
    "{df.columns}\n",
    "You can allocate records to patients with the `MPINumber` column. Conside \n",
    "The values for findings are found in the `Value` column. \n",
    "\"\"\"     },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"```python\n",
    "df['PatientAccountID'].unique()\n",
    "```\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Select all records with the diagnosis N18\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"```python\n",
    "df[(df['Finding'] == 'Diagnose') & (df['Value'].str.contains('N18'))]\n",
    "```\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Build a new dataframe with patients which were diagnosed with N18\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"```python\n",
    "diagnosed_patients = df[(df['Finding'] == 'Diagnose') & (df['Value'].str.contains('N18'))]['MPINumber'].unique()\n",
    "df_n18 = df[df['MPINumber'].isin(diagnosed_patients)]\n",
    "```\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(llm_chat, add_generation_prompt=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ - A\n",
    "How many people got diagnosed with H36 over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_template(df, \"How many patients got diagnosed with H36? Consider that each patient can have multiple findings.\", tokenizer)\n",
    "\n",
    "llm_outputs = llm.generate(query, SamplingParams(temperature=0.1, max_tokens=400))\n",
    "for i, out in enumerate(llm_outputs):\n",
    "    print('Output:')\n",
    "    print(out.outputs[0].text)\n",
    "    print('#########')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ - B\n",
    "How was the age and gender distribution of the disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_template(df, \"Given the dataframe above. Create a pie chart for the Gender distribution. \" + data_discription_str, tokenizer)\n",
    "\n",
    "llm_outputs = llm.generate(query, SamplingParams(temperature=0.1, max_tokens=400))\n",
    "for i, out in enumerate(llm_outputs):\n",
    "    print('Output:')\n",
    "    print(out.outputs[0].text)\n",
    "    print('#########')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ - C\n",
    "What were the five most common secondary diagnoses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_template_chat(df, \"Plot the five most common secondary diagnosis\", tokenizer)\n",
    "\n",
    "llm_outputs = llm.generate(query, SamplingParams(temperature=0.1, max_tokens=400))\n",
    "for i, out in enumerate(llm_outputs):\n",
    "    print('Output:')\n",
    "    print(out.outputs[0].text)\n",
    "    print('#########')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ - D\n",
    "How many HBA1C values are there for each patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_template_chat(df, \"How many the HBA1C values has each diagnosed patient?\", tokenizer)\n",
    "\n",
    "llm_outputs = llm.generate(query, SamplingParams(temperature=0.1, max_tokens=400))\n",
    "for i, out in enumerate(llm_outputs):\n",
    "    print('Output:')\n",
    "    print(out.outputs[0].text)\n",
    "    print('#########')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
